{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo para o Sensor CEI\n",
    "\n",
    "Este dataset **\"DataCEI.csv\"** possui informações dispostas em colunas sobre as características dos objetos que passam pelo sensor:\n",
    "\n",
    "* **Tamanho**:  Segue a classificação do CEI2020 (Tamanho='0' - Grande 100%).\n",
    "* **Referencia**:  Referência dinâmica do *Threshold.\n",
    "* **NumAmostra**:  Número de amostras adquiridas.\n",
    "* **Area**:  Somatório das Amplitudes das amostras.\n",
    "* **Delta**:  Máxima Amplitude da amostra.\n",
    "* **Output1**:  Peça tipo 1.\n",
    "* **Output2**:  Peça tipo 2.\n",
    "\n",
    "\n",
    "\n",
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Função do cáculo da sigmóide\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados\n",
    "\n",
    "Vamos começar lendo o arquivo Data.csv em um dataframe do pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet=pd.read_csv('arruela_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.drop(['Hora','Tamanho','Referencia'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Váriaveis do *Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Número de Peças\n",
    "\n",
    "#### Vamos classificar os grupos pelo número de peças: \n",
    "1. Grupo com uma peça\n",
    "2. Grupo com duas peças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Output2',data=DataSet,palette='RdBu_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráfico da distribuição das áreas das peças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(DataSet['Area'].dropna(),kde=False,color='darkred',bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Area',hue='Output1',data=DataSet,palette='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='NumAmostra',hue='Output1',data=DataSet,palette='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='Delta',hue='Output1',data=DataSet,palette='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As variáveis preditoras e a variável de resposta\n",
    "\n",
    "Para treinar o modelo de regressão, primeiro precisaremos dividir nossos dados em uma matriz **X** que contenha os dados das variáveis preditoras e uma matriz **y** com os dados da variável de destino.\n",
    "\n",
    "### Matrizes X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = DataSet[[ 'NumAmostra', 'Area', 'Delta']]\n",
    "#y = DataSet[['Output1','Output2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relação entre as variáveis preditoras\n",
    "\n",
    "####  Algumas questões importantes\n",
    "1. Pelo menos um dos preditores ***x1, x2, ... ,x5***  é útil na previsão da resposta?\n",
    "2. Todos os preditores ajudam a explicar **y**, ou apenas um subconjunto dos preditores?\n",
    "3. Quão bem o modelo se ajusta aos dados?\n",
    "4. Dado um conjunto de valores de previsão, quais valores de resposta devemos prever e quais as métricas indicam um bom modelo de previsão?\n",
    "\n",
    "**Gráficos simples de dispersão**\n",
    "\n",
    "Pelos gráficos abaixo percebemos ... nossa variável de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(DataSet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapa de Calor**\n",
    "\n",
    "O gráfico abaixo mostra através de uma escala de cores a correlação entre as variáveis do *Dataset*. Se observarmos as cores deste gráfico, a variável preditora **'Area'** possui maior correlação com a variável de resposta **'Output'** e a variável **'NumAmostra'** a menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(DataSet.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "DataScaled=scaler.fit_transform(DataSet)\n",
    "DataSetScaled=pd.DataFrame(np.array(DataScaled),columns = ['NumAmostra', 'Area', 'Delta', 'Output1','Output2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSetScaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de dados para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataSetScaled.drop(['Output1', 'Output2'],axis=1)\n",
    "y = DataSet[['Output1','Output2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando os dados de treinamento e de validação\n",
    "\n",
    "Agora vamos dividir os dados em um conjunto de treinamento e um conjunto de testes. Vamos treinar o modelo no conjunto de treinamento, em seguida, usar o conjunto de teste para validar o modelo.\n",
    "\n",
    "Em nosso exemplo iremos separar de forma randômica 33% dos dados para validação. Estes dados não serão utilizados para determinação dos coeficientes preditores do modelo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)\n",
    "\n",
    "print(y_test)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o Modelo de MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamanho do DataSet de Treinamento\n",
    "n_records, n_features = X_train.shape\n",
    "\n",
    "#Arquitetura da MPL\n",
    "N_input = 3\n",
    "N_hidden = 4\n",
    "N_output = 2\n",
    "learnrate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialização dos pesos da MPL (Aleatório)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pesos da Camada Oculta (Inicialização Aleatória)\n",
    "weights_input_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "print('Pesos da Camada Oculta:')\n",
    "print(weights_input_hidden)\n",
    "\n",
    "#Pesos da Camada de Saída (Inicialização Aleatória)\n",
    "weights_hidden_output = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))\n",
    "print('Pesos da Camada de Saída:')\n",
    "print(weights_hidden_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "last_loss=None\n",
    "EvolucaoError=[]\n",
    "IndiceError=[]\n",
    "\n",
    "for e in range(epochs):\n",
    "    delta_w_i_h = np.zeros(weights_input_hidden.shape)\n",
    "    delta_w_h_o = np.zeros(weights_hidden_output.shape)\n",
    "    for xi, yi in zip(X_train.values, y_train.values):\n",
    "        \n",
    "# Forward Pass\n",
    "        #Camada oculta\n",
    "        #Calcule a combinação linear de entradas e pesos sinápticos\n",
    "        hidden_layer_input = np.dot(xi, weights_input_hidden)\n",
    "        #Aplicado a função de ativação\n",
    "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    \n",
    "        #Camada de Saída\n",
    "        #Calcule a combinação linear de entradas e pesos sinápticos\n",
    "        output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "\n",
    "        #Aplicado a função de ativação \n",
    "        output = sigmoid(output_layer_in)\n",
    "        #print('As saídas da rede são',output)\n",
    "#-------------------------------------------    \n",
    "    \n",
    "# Backward Pass\n",
    "        ## TODO: Cálculo do Erro\n",
    "        error = yi - output\n",
    "    \n",
    "        # TODO: Calcule o termo de erro de saída (Gradiente da Camada de Saída)\n",
    "        output_error_term = error * output * (1 - output)\n",
    "\n",
    "        # TODO: Calcule a contribuição da camada oculta para o erro\n",
    "        hidden_error = np.dot(weights_hidden_output,output_error_term)\n",
    "    \n",
    "        # TODO: Calcule o termo de erro da camada oculta (Gradiente da Camada Oculta)\n",
    "        hidden_error_term = hidden_error * hidden_layer_output * (1 - hidden_layer_output)\n",
    "    \n",
    "        # TODO: Calcule a variação do peso da camada de saída\n",
    "        delta_w_h_o += output_error_term*hidden_layer_output[:, None]\n",
    "\n",
    "        # TODO: Calcule a variação do peso da camada oculta\n",
    "        delta_w_i_h += hidden_error_term * xi[:, None]\n",
    "        \n",
    "    #Atualização dos pesos na época em questão\n",
    "    weights_input_hidden += learnrate * delta_w_i_h / n_records\n",
    "    weights_hidden_output += learnrate * delta_w_h_o / n_records\n",
    "    \n",
    "    \n",
    "    # Imprimir o erro quadrático médio no conjunto de treinamento\n",
    "    \n",
    "    if  e % (epochs / 20) == 0:\n",
    "        hidden_output = sigmoid(np.dot(xi, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - yi) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Erro quadrático no treinamento: \", loss, \" Atenção: O erro está aumentando\")\n",
    "        else:\n",
    "            print(\"Erro quadrático no treinamento: \", loss)\n",
    "        last_loss = loss\n",
    "         \n",
    "        EvolucaoError.append(loss)\n",
    "        IndiceError.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gráfico da Evolução do Erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(IndiceError, EvolucaoError, 'r') # 'r' is the color red\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Erro Quadrático')\n",
    "plt.title('Evolução do Erro no treinamento da MPL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule a precisão dos dados de teste\n",
    "n_records, n_features = X_test.shape\n",
    "predictions=0\n",
    "\n",
    "for xi, yi in zip(X_test.values, y_test.values):\n",
    "\n",
    "# Forward Pass\n",
    "        #Camada oculta\n",
    "        #Calcule a combinação linear de entradas e pesos sinápticos\n",
    "        hidden_layer_input = np.dot(xi, weights_input_hidden)\n",
    "        #Aplicado a função de ativação\n",
    "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    \n",
    "        #Camada de Saída\n",
    "        #Calcule a combinação linear de entradas e pesos sinápticos\n",
    "        output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "\n",
    "        #Aplicado a função de ativação \n",
    "        output = sigmoid(output_layer_in)\n",
    "\n",
    "#-------------------------------------------    \n",
    "    \n",
    "#Cálculo do Erro da Predição\n",
    "        ## TODO: Cálculo do Erro        \n",
    "        if (output[0]>output[1]):\n",
    "            if (yi[0]>yi[1]):\n",
    "                predictions+=1\n",
    "                \n",
    "        if (output[1]>=output[0]):\n",
    "            if (yi[1]>yi[0]):\n",
    "                predictions+=1\n",
    "\n",
    "print(\"A Acurácia da Predição é de: {:.3f}\".format(predictions/n_records))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
